# CUDA Course

GitHub Repo for CUDA Course on FreeCodeCamp

> Note: This course is designed for Ubuntu Linux. Windows users can use Windows Subsystem for Linux or Docker containers to simulate the ubuntu Linux environment.

## Table of Contents

1. [The Deep Learning Ecosystem](01_Deep_Learning_Ecosystem/README.md)
2. [Setup/Installation](02_Setup/README.md)
3. [C/C++ Review](03_C_and_C++_Review/README.md)
4. [Gentle Intro to GPUs](04_Gentle_Intro_to_GPUs/README.md)
5. [Writing Your First Kernels](05_Writing_your_First_Kernels/README.md)
6. [CUDA APIs (cuBLAS, cuDNN, etc)](06_CUDA_APIs/README.md)
7. [Optimizing Matrix Multiplication](07_Faster_Matmul/README.md)
8. [Triton](08_Triton/README.md)
9. [PyTorch Extensions (CUDA)](08_PyTorch_Extensions/README.md)
10. [Final Project](09_Final_Project/README.md)


## Course Philosophy

This course aims to:

- Lower the barrier to entry for HPC jobs
- Provide a foundation for understanding projects like Karpathy's [llm.c](https://github.com/karpathy/llm.c)
- Consolidate scattered CUDA programming resources into a comprehensive, organized course

## Overview

- Focus on GPU kernel optimization for performance improvement
- Cover CUDA, PyTorch, and Triton
- Emphasis on technical details of writing faster kernels
- Tailored for NVIDIA GPUs
- Culminates in a simple MLP MNIST project in CUDA

## Prerequisites

- Python programming (required)
- Basic differentiation and vector calculus for backprop (recommended)
- Linear algebra fundamentals (recommended)

## Key Takeaways

- Optimizing existing implementations
- Building CUDA kernels for cutting-edge research
- Understanding GPU performance bottlenecks, especially memory bandwidth

## Hardware Requirements

- Any NVIDIA GTX, RTX, or datacenter level GPU
- Cloud GPU options available for those without local hardware

## Use Cases for CUDA/GPU Programming

- Deep Learning (primary focus of this course)
- Graphics and Ray-tracing
- Fluid Simulation
- Video Editing
- Crypto Mining
- 3D modeling
- Anything that requires parallel processing with large arrays

## Resources

- GitHub repo (this repository)
- Stack Overflow
- NVIDIA Developer Forums
- NVIDIA and PyTorch documentation
- LLMs for navigating the space

